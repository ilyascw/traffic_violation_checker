{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Загрузка модели YOLO \n",
    "model = YOLO('D:\\\\traffic_violation_checker\\\\models\\\\best.pt')  #путь к  .pt файлу\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "# Загрузим маппинг классов из файла YAML\n",
    "with open('D:\\\\traffic_violation_checker\\\\models\\\\class_labels.yaml', 'r') as f:\n",
    "    yaml_dict = yaml.safe_load(f)\n",
    "class_mapping = yaml_dict['names']  # {ID: name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 1 421, 1 423, 1 412, 282.0ms\n",
      "Speed: 6.7ms preprocess, 282.0ms inference, 11.1ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "# Загрузка изображения\n",
    "image = cv2.imread('D:\\\\traffic_violation_checker\\\\data\\\\img\\\\example3.png')  #путь к вашему изображению\n",
    "\n",
    "# Прогнозирование\n",
    "results = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: '21', 1: '123', 2: '117', 3: '324', 4: '821', 5: '520', 6: '5191', 7: '516', 8: '325', 9: '616', 10: '715', 11: '22', 12: '24', 13: '8131', 14: '421', 15: '1203', 16: '125', 17: '34', 18: '832', 19: '341', 20: '416', 21: '423', 22: '411', 23: '133', 24: '5155', 25: '327', 26: '115', 27: '4121', 28: '631', 29: '811', 30: '67', 31: '5153', 32: '73', 33: '119', 34: '64', 35: '814', 36: '88', 37: '116', 38: '1111', 39: '66', 40: '5151', 41: '72', 42: '5152', 43: '712', 44: '318', 45: '56', 46: '55', 47: '74', 48: '412', 49: '822', 50: '711', 51: '122', 52: '127', 53: '232', 54: '51522', 55: '18', 56: '313', 57: '23', 58: '233', 59: '77', 60: '111', 61: '813', 62: '1122', 63: '120', 64: '112', 65: '332', 66: '25', 67: '31', 68: '482', 69: '320', 70: '32', 71: '236', 72: '522', 73: '518', 74: '75', 75: '841', 76: '314', 77: '12', 78: '1202', 79: '414', 80: '76', 81: '813', 82: '831', 83: '43', 84: '415', 85: '823', 86: '824', 87: '131', 88: '310', 89: '422', 90: '71', 91: '328', 92: '413', 93: '54', 94: '53', 95: '682', 96: '331', 97: '62', 98: '121', 99: '321', 100: '113', 101: '114', 102: '234', 103: '483', 104: '6152', 105: '26', 106: '3182', 107: '4122', 108: '17', 109: '319', 110: '118', 111: '27', 112: '854', 113: '5157', 114: '514', 115: '521', 116: '11', 117: '6151', 118: '864', 119: '815', 120: '311', 121: '818', 122: '844', 123: '330', 124: '571', 125: '572', 126: '15', 127: '329', 128: '512', 129: '316', 130: '130', 131: '511', 132: '16', 133: '862', 134: '683', 135: '312', 136: '843', 137: '58', 138: '817', 139: '36', 140: '126', 141: '852', 142: '517', 143: '110', 144: '718', 145: '714'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 249, 255],\n",
       "         [255, 249, 255],\n",
       "         [255, 249, 255],\n",
       "         ...,\n",
       "         [255, 249, 255],\n",
       "         [255, 249, 255],\n",
       "         [255, 249, 255]],\n",
       " \n",
       "        [[255, 249, 255],\n",
       "         [255, 249, 255],\n",
       "         [255, 249, 255],\n",
       "         ...,\n",
       "         [255, 249, 255],\n",
       "         [255, 249, 255],\n",
       "         [255, 249, 255]],\n",
       " \n",
       "        [[255, 249, 255],\n",
       "         [255, 249, 255],\n",
       "         [255, 249, 255],\n",
       "         ...,\n",
       "         [255, 249, 255],\n",
       "         [255, 249, 255],\n",
       "         [255, 249, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 74,  84,  84],\n",
       "         [ 69,  79,  79],\n",
       "         [ 68,  78,  78],\n",
       "         ...,\n",
       "         [ 57,  60,  52],\n",
       "         [ 59,  61,  55],\n",
       "         [ 60,  61,  55]],\n",
       " \n",
       "        [[ 83,  93,  95],\n",
       "         [100, 111, 112],\n",
       "         [ 87,  98,  99],\n",
       "         ...,\n",
       "         [ 56,  59,  52],\n",
       "         [ 59,  61,  54],\n",
       "         [ 60,  62,  55]],\n",
       " \n",
       "        [[ 95, 107, 109],\n",
       "         [ 99, 110, 112],\n",
       "         [ 96, 108, 110],\n",
       "         ...,\n",
       "         [ 56,  59,  51],\n",
       "         [ 58,  60,  52],\n",
       "         [ 60,  62,  55]]], dtype=uint8)\n",
       " orig_shape: (748, 1516)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 6.674051284790039, 'inference': 282.0467948913574, 'postprocess': 11.116743087768555}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([21., 48., 14.])\n",
       "conf: tensor([0.7117, 0.7083, 0.6269])\n",
       "data: tensor([[7.5482e+02, 8.3594e+01, 8.0961e+02, 1.4085e+02, 7.1172e-01, 2.1000e+01],\n",
       "        [8.4551e+02, 1.5958e+02, 8.8384e+02, 1.9794e+02, 7.0828e-01, 4.8000e+01],\n",
       "        [5.6759e+01, 1.2242e+02, 9.3974e+01, 1.6644e+02, 6.2691e-01, 1.4000e+01]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (748, 1516)\n",
       "shape: torch.Size([3, 6])\n",
       "xywh: tensor([[782.2118, 112.2214,  54.7912,  57.2555],\n",
       "        [864.6715, 178.7626,  38.3294,  38.3629],\n",
       "        [ 75.3665, 144.4263,  37.2157,  44.0185]])\n",
       "xywhn: tensor([[0.5160, 0.1500, 0.0361, 0.0765],\n",
       "        [0.5704, 0.2390, 0.0253, 0.0513],\n",
       "        [0.0497, 0.1931, 0.0245, 0.0588]])\n",
       "xyxy: tensor([[754.8162,  83.5936, 809.6074, 140.8491],\n",
       "        [845.5068, 159.5811, 883.8362, 197.9441],\n",
       "        [ 56.7587, 122.4170,  93.9744, 166.4355]])\n",
       "xyxyn: tensor([[0.4979, 0.1118, 0.5340, 0.1883],\n",
       "        [0.5577, 0.2133, 0.5830, 0.2646],\n",
       "        [0.0374, 0.1637, 0.0620, 0.2225]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получаем bounding boxes и имена классов\n",
    "boxes = results[0].boxes  # Список боксов (bounding boxes)\n",
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box 1:\n",
      "  Coordinates: (x: 782.2117919921875, y: 112.22137451171875, w: 54.79119873046875, h: 57.255462646484375)\n",
      "  Class: 4.2.3\n",
      "Box 2:\n",
      "  Coordinates: (x: 864.6715087890625, y: 178.76260375976562, w: 38.32940673828125, h: 38.36293029785156)\n",
      "  Class: 4.1.2\n",
      "Box 3:\n",
      "  Coordinates: (x: 75.36650848388672, y: 144.42630004882812, w: 37.2157096862793, h: 44.01850891113281)\n",
      "  Class: 4.2.1\n"
     ]
    }
   ],
   "source": [
    "# Выведем bounding boxes и классы\n",
    "for i, (box, cls_id) in enumerate(zip(boxes.xywh, boxes.cls)):\n",
    "    x, y, w, h = box  # координаты бокса в формате [x_center, y_center, width, height]\n",
    "    class_name = class_mapping[int(cls_id)]  # Имя класса по ID из YAML\n",
    "\n",
    "    print(f'Box {i + 1}:')\n",
    "    print(f'  Coordinates: (x: {x}, y: {y}, w: {w}, h: {h})')\n",
    "    print(f'  Class: {class_name}')\n",
    "\n",
    "    # Если нужно нарисовать боксы на изображении:\n",
    "    x1, y1 = int(x - w / 2), int(y - h / 2)\n",
    "    x2, y2 = int(x + w / 2), int(y + h / 2)\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Рисуем бокс (зеленый)\n",
    "\n",
    "    #метка класса\n",
    "    cv2.putText(image, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "# Отображаем результат с бокса\n",
    "cv2.imshow('Result', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tr_checker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
